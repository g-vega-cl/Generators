{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crD_cBhQCCmU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qF2UykguCU2g",
    "outputId": "87cc4970-d922-41fd-ed27-f0d61b944803"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIha6o3RCVuU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LajmacsACard"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 50000\n",
    "os.chdir(\"/content/Data\")\n",
    "fileList = os.listdir()\n",
    "os.chdir(fileList[22])\n",
    "sample_train_images = np.load(fileList[22])\n",
    "sample_train_images = sample_train_images.reshape(sample_train_images.shape[0], sample_train_images.shape[1], sample_train_images.shape[2],sample_train_images.shape[3]).astype('float32')\n",
    "sample_train_images = ((sample_train_images -127.5) / 127.5)*1 #Esto te da valores de -1 a 1\n",
    "sample_real_batch_dataset = tf.data.Dataset.from_tensor_slices(sample_train_images.reshape(sample_train_images.shape[0],sample_train_images.shape[1],sample_train_images.shape[2],sample_train_images.shape[3])).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "sample_real_image_batch = next(iter(sample_real_batch_dataset))\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQFSZh-aCme0"
   },
   "source": [
    "# The discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDYLS2I5CkyT"
   },
   "outputs": [],
   "source": [
    "class generate_discriminator_model(keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    #first model\n",
    "    self.conv2D_1_16 = tf.keras.layers.Conv2D(64, kernel_size = (17,9),\n",
    "                                            padding='same',  \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            input_shape=[16,8,4],\n",
    "                                            activation = tf.nn.leaky_relu)    \n",
    "    self.drop_1_16 = tf.keras.layers.Dropout(rate = .3) \n",
    "    self.conv2D_2_16 = tf.keras.layers.Conv2D(32, kernel_size = (16,8),\n",
    "                                            padding='same',  \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            activation = tf.nn.leaky_relu)    \n",
    "    self.drop_2_16 = tf.keras.layers.Dropout(rate = .1)           \n",
    "    self.flatten_16 = tf.keras.layers.Flatten()\n",
    "    self.dense_1_16 =tf.keras.layers.Dense(32, activation = tf.nn.leaky_relu)\n",
    "    self.dense_out_16 = tf.keras.layers.Dense(1, activation = \"linear\")\n",
    "\n",
    "\n",
    "\n",
    "    self.MaxPooling_32To16 = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=None, padding=\"valid\",\n",
    "    data_format=None)    \n",
    "\n",
    "    # Second model\n",
    "    self.conv2D_1_32 = tf.keras.layers.Conv2D(16, kernel_size = (32,16),\n",
    "                                            strides = (1,1),\n",
    "                                            padding='same',  \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            input_shape=[32,16,4],\n",
    "                                            activation = tf.nn.leaky_relu)\n",
    "    self.drop_1_32 = tf.keras.layers.Dropout(rate = .3) \n",
    "\n",
    "    self.conv2D_2_32 = tf.keras.layers.Conv2D(4, kernel_size = (5,5),\n",
    "                                            strides = (2,2),\n",
    "                                            padding='same',  \n",
    "                                            kernel_initializer='he_normal',\n",
    "                                            input_shape=[32,16,4],\n",
    "                                            activation = tf.nn.leaky_relu)\n",
    "    self.drop_2_32 = tf.keras.layers.Dropout(rate = .1) \n",
    "        \n",
    "\n",
    "\n",
    "    self.MaxPooling_64To32 = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=None, padding=\"valid\",\n",
    "    data_format=None)    \n",
    "  \n",
    "\n",
    "  def first_call(self, input_tensor_16x8, training = True):\n",
    "    x = self.conv2D_1_16(input_tensor_16x8)\n",
    "    x = self.drop_1_16(x)    \n",
    "    x = self.conv2D_2_16(x)\n",
    "    x = self.drop_2_16(x)  \n",
    "    x = self.flatten_16(x)\n",
    "    x = self.dense_1_16(x)\n",
    "    x = self.dense_out_16(x)\n",
    "\n",
    "    return x  \n",
    "  \n",
    "  def second_call(self, input_tensor_32x16, alpha):\n",
    "    x_old = self.MaxPooling_32To16(input_tensor_32x16)  #downsampling\n",
    "    x_old = self.first_call(x_old)\n",
    "    \n",
    "    #Added layers\n",
    "    x_new = self.conv2D_1_32(input_tensor_32x16)\n",
    "    x_new = self.drop_1_32(x_new)\n",
    "    x_new = self.conv2D_2_32(input_tensor_32x16) #converts to 16\n",
    "    x_new = self.drop_2_32(x_new)    \n",
    "    x_new = self.first_call(x_new)\n",
    "\n",
    "    x = ((1-alpha) * x_old) + (alpha * x_new)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_PYbPpoYCer"
   },
   "source": [
    "### Optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afOmtn-BIHn8"
   },
   "outputs": [],
   "source": [
    "discriminator = generate_discriminator_model()\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFGhAKcYINFU"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator_predictions_real, discriminator_predictions_fake):\n",
    "  loss = -(discriminator_predictions_real) + discriminator_predictions_fake\n",
    "  return tf.reduce_mean(loss)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdxDMenrJ7d4"
   },
   "source": [
    "# The generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuWy6V2AJ2_G"
   },
   "outputs": [],
   "source": [
    "class generate_generator_model(keras.Model):\n",
    "  def __init__(self, latent_dim = 100):\n",
    "    super().__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "    #Model part 1\n",
    "    self.dense_1_16 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu,\n",
    "                                         input_shape= (self.latent_dim, ))\n",
    "    \n",
    "    self.dense_2_16 = tf.keras.layers.Dense(units=1024, activation=tf.nn.leaky_relu)\n",
    "    \n",
    "    self.dense_3_16 = tf.keras.layers.Dense(units=16*8*4, activation=tf.nn.leaky_relu)  \n",
    "\n",
    "    self.reshape_1_16 = tf.keras.layers.Reshape(target_shape=(16,8,4))\n",
    "    self.conv2DT_1_16 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=64,\n",
    "              kernel_size=(16,8),\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation= tf.nn.leaky_relu)\n",
    "    \n",
    "    self.batchNorm_2_16 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2DT_2_16 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=16,\n",
    "              kernel_size=(15,7),\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation=tf.nn.leaky_relu)\n",
    "\n",
    "    self.batchNorm_3_16 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2DT_3_16 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=16,\n",
    "              kernel_size=(13,5),\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation=tf.nn.leaky_relu)      \n",
    "    \n",
    "    self.batchNorm_4_16 = tf.keras.layers.BatchNormalization()\n",
    "    self.conv2DT_4_16 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=4,\n",
    "              kernel_size=(5,5),\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation='linear')    \n",
    "    \n",
    "\n",
    "    self.UpSampling2D_16to32 = tf.keras.layers.UpSampling2D(\n",
    "        size=(2, 2), data_format=None, interpolation='nearest')\n",
    "    \n",
    "    # Model part 2 #################################\n",
    "    self.reshape_1_32 = tf.keras.layers.Reshape(target_shape=(16, 8, 4)) #Shape at which it enters\n",
    "    self.conv2DT_1_32 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=8,\n",
    "              kernel_size=(32,16),\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation=tf.nn.leaky_relu)\n",
    "    self.batchNorm_1_32 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2DT_2_32 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=16,\n",
    "              kernel_size=(31,15),\n",
    "              strides=(2, 2),\n",
    "              padding=\"SAME\",\n",
    "              activation=tf.nn.leaky_relu)\n",
    "    self.batchNorm_2_32 = tf.keras.layers.BatchNormalization()    \n",
    "\n",
    "    self.conv2DT_3_32 = tf.keras.layers.Conv2DTranspose(\n",
    "              filters=4,\n",
    "              kernel_size=(5,5),\n",
    "              strides=(1, 1),\n",
    "              padding=\"SAME\",\n",
    "              activation='linear')\n",
    "    \n",
    "\n",
    "    self.UpSampling2D_32to64 = tf.keras.layers.UpSampling2D(\n",
    "        size=(2, 2), data_format=None, interpolation='nearest')\n",
    "\n",
    "  def call_first(self, input_noise, training = True):\n",
    "      x = self.dense_1_16(input_noise)\n",
    "      x = self.dense_2_16(x)  \n",
    "      x = self.dense_3_16(x)  \n",
    "      x = self.reshape_1_16(x)\n",
    "      x = self.conv2DT_1_16(x)\n",
    "      x = self.batchNorm_2_16(x)\n",
    "      x = self.conv2DT_2_16(x)\n",
    "      x = self.batchNorm_3_16(x)\n",
    "      x = self.conv2DT_3_16(x)\n",
    "      x = self.batchNorm_4_16(x)\n",
    "      x = self.conv2DT_4_16(x)    \n",
    "      #x = tf.clip_by_value(x,-1,1) #should I?\n",
    "      return x\n",
    "  \n",
    "  def call_second(self, input_noise, alpha):\n",
    "    x_old = self.call_first(input_noise)\n",
    "    x_old = self.UpSampling2D_16to32(x_old) # now we get 32 image\n",
    "\n",
    "    ########################\n",
    "    # Now comes the model but with the new layer (32)\n",
    "    x_new = self.call_first(input_noise)\n",
    "    \n",
    "    # Model 2\n",
    "    x_new = self.reshape_1_32(x_new)\n",
    "    x_new = self.conv2DT_1_32(x_new)\n",
    "    x_new = self.batchNorm_1_32(x_new)\n",
    "    x_new = self.conv2DT_2_32(x_new)\n",
    "    x_new = self.batchNorm_2_32(x_new)\n",
    "    x_new = self.conv2DT_3_32(x_new)\n",
    "\n",
    "    x = ((1-alpha) * x_old) + (alpha * x_new)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hvay0Xu2YEyI"
   },
   "source": [
    "### Generator Optimizers and loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJ9wMoU6YH2e"
   },
   "outputs": [],
   "source": [
    "generator = generate_generator_model()\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHSBKxW4YQtg"
   },
   "outputs": [],
   "source": [
    "def generator_loss(d_fake_predictions):\n",
    "  loss = -tf.reduce_mean(d_fake_predictions)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKVgekZLYaaA"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "This needs to be \"modular\", when one model at one resolution converges, we do the next resolution.\n",
    "\n",
    "I will do it manually.\n",
    "(train one, then second one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mynHNBbMsaiM"
   },
   "source": [
    "Define checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2cDe5XdQXZeA",
    "outputId": "bac50c9a-bc33-46e8-acfe-a9af45237f38"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aO2E8bgscKa"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h9Ny3BLzsayL"
   },
   "source": [
    "The training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIWT7ZwttMI8"
   },
   "outputs": [],
   "source": [
    "def get_reduced_weights_or_gradients(values):\n",
    "    for values_i in range(len(values)):\n",
    "            if values_i == 0:\n",
    "                values_red = tf.reduce_mean(values[values_i])\n",
    "            else:\n",
    "                values_red += tf.reduce_mean(values[values_i])\n",
    "\n",
    "    values_red = values_red/len(values)    \n",
    "    \n",
    "    return values_red\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeyypYu2ZhAG"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        for _ in range(3):\n",
    "          noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "          generated_images = generator.call_first(noise)\n",
    "          with tf.GradientTape() as disc_tape:\n",
    "                discriminator_predictions_fake = discriminator.first_call(generated_images)\n",
    "                discriminator_predictions_real = discriminator.first_call(images)\n",
    "                ## Gradient penalty process\n",
    "                with tf.GradientTape() as disc_tape_gp:\n",
    "                    epsilon = tf.random.uniform([BATCH_SIZE,1,1,1], minval=0, maxval = 1)\n",
    "                    differences = generated_images - images\n",
    "                    interpolates  = images + (epsilon * differences)\n",
    "                    disc_tape_gp.watch(interpolates)\n",
    "                    discriminator_predictions_interpolates = discriminator.first_call(interpolates)\n",
    "                    gradients_interpolates = disc_tape_gp.gradient(discriminator_predictions_interpolates,\n",
    "                                                               [interpolates])[0] # Not sure why the [0] or the [inter]\n",
    "\n",
    "                    slopes = tf.sqrt(tf.reduce_sum(tf.math.square(gradients_interpolates), axis = [1,2,3]))\n",
    "                    gradient_penalty = 10 * tf.reduce_mean((slopes - 1)**2)\n",
    "\n",
    "                    disc_loss = discriminator_loss(discriminator_predictions_real, discriminator_predictions_fake)\n",
    "                    disc_loss += gradient_penalty\n",
    "\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)  \n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "        gen_loss = generator_loss(discriminator_predictions_fake)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)  \n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    \n",
    "\n",
    "    disc_grads_reduced = get_reduced_weights_or_gradients(gradients_of_discriminator)\n",
    "    disc_weights_reduced = get_reduced_weights_or_gradients(discriminator.trainable_variables)\n",
    "    gen_grads_reduced = get_reduced_weights_or_gradients(gradients_of_generator)\n",
    "    gen_weights_reduced = get_reduced_weights_or_gradients(generator.trainable_variables)\n",
    "    \n",
    "    \n",
    "    return tf.reduce_mean(discriminator_predictions_real), tf.reduce_mean(discriminator_predictions_fake), disc_loss, disc_grads_reduced, gen_grads_reduced, disc_weights_reduced,gen_weights_reduced\n",
    "  \n",
    "\n",
    "@tf.function\n",
    "def train_step_2(images,alpha):\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        for _ in range(3):\n",
    "          noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "          generated_images = generator.call_second(noise, alpha)\n",
    "          with tf.GradientTape() as disc_tape:\n",
    "                discriminator_predictions_fake = discriminator.second_call(generated_images, alpha) #Change call\n",
    "                discriminator_predictions_real = discriminator.second_call(images, alpha) #Change call\n",
    "                ## Gradient penalty process\n",
    "                with tf.GradientTape() as disc_tape_gp:\n",
    "                    epsilon = tf.random.uniform([BATCH_SIZE,1,1,1], minval=0, maxval = 1)\n",
    "                    differences = generated_images - images\n",
    "                    interpolates  = images + (epsilon * differences)\n",
    "                    disc_tape_gp.watch(interpolates)\n",
    "                    discriminator_predictions_interpolates = discriminator.second_call(interpolates, alpha) #Change call\n",
    "                    gradients_interpolates = disc_tape_gp.gradient(discriminator_predictions_interpolates,\n",
    "                                                               [interpolates])[0] # Not sure why the [0] or the [inter]\n",
    "\n",
    "                    slopes = tf.sqrt(tf.reduce_sum(tf.math.square(gradients_interpolates), axis = [1,2,3]))\n",
    "                    gradient_penalty = 10 * tf.reduce_mean((slopes - 1)**2)\n",
    "\n",
    "                    disc_loss = discriminator_loss(discriminator_predictions_real, discriminator_predictions_fake)\n",
    "                    disc_loss += gradient_penalty\n",
    "\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)  \n",
    "                discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))                \n",
    "\n",
    "        gen_loss = generator_loss(discriminator_predictions_fake)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)  \n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    disc_grads_reduced = get_reduced_weights_or_gradients(gradients_of_discriminator)\n",
    "    disc_weights_reduced = get_reduced_weights_or_gradients(discriminator.trainable_variables)\n",
    "    gen_grads_reduced = get_reduced_weights_or_gradients(gradients_of_generator)\n",
    "    gen_weights_reduced = get_reduced_weights_or_gradients(generator.trainable_variables)\n",
    "\n",
    "    return tf.reduce_mean(discriminator_predictions_real), tf.reduce_mean(discriminator_predictions_fake), disc_loss, disc_grads_reduced, gen_grads_reduced, disc_weights_reduced,gen_weights_reduced\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngEu4-VfsMXC"
   },
   "outputs": [],
   "source": [
    "discLosses = []\n",
    "discGrads = []\n",
    "genGrads = []\n",
    "discWeights = []\n",
    "genWeights = []\n",
    "\n",
    "def train(dataset, epochs, dataset_num,call_number,alpha):\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    for image_batch in dataset:\n",
    "      if(call_number == 1):\n",
    "        disc_pred_real, disc_pred_fake, disc_loss, disc_grads,gen_grads,disc_weight,gen_weight = train_step(image_batch)    \n",
    "      elif(call_number == 2):\n",
    "        disc_pred_real, disc_pred_fake, disc_loss, disc_grads,gen_grads,disc_weight,gen_weight = train_step_2(image_batch,alpha = alpha)    \n",
    "      \n",
    "      discLosses.append(disc_loss)\n",
    "      discGrads.append(disc_grads)\n",
    "      genGrads.append(gen_grads)\n",
    "      discWeights.append(disc_weight)\n",
    "      genWeights.append(gen_weight)\n",
    "      \n",
    "    # Save the model every X epochs\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "      #checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "      print(\"disc_pred_real \", disc_pred_real, \"disc_pred_fake\", disc_pred_fake)\n",
    "      print(\" disc loss: \", disc_loss)\n",
    "      print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start), \" dataset_num: \", dataset_num)\n",
    "    \n",
    "      noise = tf.random.normal([2, 100]) #Batch size changed to 2\n",
    "      if(call_number == 1):\n",
    "        sample_image = generator.call_first(noise)[0]\n",
    "      elif(call_number == 2):\n",
    "        sample_image = generator.call_second(noise, alpha = alpha)[0]\n",
    "      \n",
    "      fig = plt.figure(figsize = (15,3))\n",
    "      plt.subplot(1,3,1)\n",
    "      plt.imshow(sample_image)\n",
    "      plt.subplot(1,3,2)\n",
    "      plt.plot(np.array(discWeights).tolist())\n",
    "      plt.subplot(1,3,3)\n",
    "      plt.plot(np.array(genWeights).tolist())        \n",
    "      #plt.axis('off')\n",
    "      plt.show()\n",
    "      \n",
    "      fig2 = plt.figure(figsize = (15,3))\n",
    "      plt.subplot(1,3,1)\n",
    "      plt.plot(np.array(discGrads).tolist())\n",
    "      plt.subplot(1,3,2)\n",
    "      plt.plot(np.array(genGrads).tolist())\n",
    "      plt.subplot(1,3,3)\n",
    "      plt.plot(np.array(discLosses).tolist())\n",
    "      plt.tight_layout()\n",
    "      plt.show()\n",
    "      clear_output(wait=True)\n",
    "  # Generate after the final epoch\n",
    "  clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPQ5a943snX9"
   },
   "source": [
    "For the first loop I need to downsample the real images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_M99Db9_tOZD"
   },
   "outputs": [],
   "source": [
    "maxPooling2D = tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCCfwd4Gtys0"
   },
   "source": [
    "### Train the first model (32x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "Av3dV0pcsfXP",
    "outputId": "a255d1e4-926f-4222-abac-dc73e1bd14f4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/Data\")\n",
    "fileList = os.listdir()\n",
    "EPOCHS = 200\n",
    "try:\n",
    "  fileList.remove(\".ipynb_checkpoints\")\n",
    "  fileList.remove(\"training_checkpoints\")\n",
    "  fileList.remove(\"training_checkpoints.zip\")\n",
    "except: \n",
    "  pass\n",
    "dataset_num = 0\n",
    "indexList = list(range(len(fileList)))\n",
    "call_number = 2\n",
    "alpha = 0\n",
    "for i in range(len(fileList)):\n",
    "    val = random.choice(indexList)\n",
    "    indexList.remove(val)\n",
    "    os.chdir(fileList[val])\n",
    "    train_images = np.load(fileList[val])\n",
    "    train_images = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2],train_images.shape[3]).astype('float32')\n",
    "    train_images = ((train_images-127.5) / 127.5)*1 #Esto te da valores de -.1 a .1\n",
    "    \n",
    "    train_images = maxPooling2D(train_images) # serían 128x64\n",
    "    train_images =  maxPooling2D(train_images) # serían 64x32  \n",
    "    train_images =  maxPooling2D(train_images) # serían 32x16    \n",
    "    #train_images =  maxPooling2D(train_images) # serían 16x8       \n",
    "    train_images = np.array(train_images)    \n",
    "    os.chdir(\"..\")     \n",
    "    # Porque son los que regresa el generador\n",
    "    batch_dataset = tf.data.Dataset.from_tensor_slices(train_images.reshape(train_images.shape[0],train_images.shape[1],train_images.shape[2],train_images.shape[3])).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "    train(batch_dataset, EPOCHS, dataset_num,call_number = call_number, alpha = alpha)\n",
    "    \n",
    "    if alpha < 1:\n",
    "      alpha += .05\n",
    "    elif alpha == 1:\n",
    "      pass\n",
    "    else: \n",
    "      alpha = 1\n",
    "\n",
    "    print(\"dataset_num: \", dataset_num)\n",
    "    dataset_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Q3UdYcutMJO"
   },
   "source": [
    "### Test the models and analyze pixel distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "6ogBUNP7wIE0",
    "outputId": "e4361499-6d7f-4e0d-fc53-384306801837",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "generated_images = generator.call_second(noise,1)\n",
    "plt.imshow(generated_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nS4oPRFetMJV",
    "outputId": "2c38dd7f-e503-4eac-ecc2-898c00802562"
   },
   "outputs": [],
   "source": [
    "discriminator.second_call(generated_images,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "RKUwOSfG1Bsp",
    "outputId": "7cc85eac-c84f-4a91-e9f4-7f71ba270f01"
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_images[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "id": "_T7T1PGLeqJ7",
    "outputId": "41abad09-4323-4727-fe3c-3a9da958385f"
   },
   "outputs": [],
   "source": [
    "flatGenerations = (tf.reshape(generated_images, [-1]))\n",
    "plt.hist(flatGenerations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "CYMtBdtLtMJg",
    "outputId": "8619d350-4bfb-4adf-c06d-7630ba793160"
   },
   "outputs": [],
   "source": [
    "flatImages = (tf.reshape(train_images, [-1]))\n",
    "plt.hist(flatImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aq6KCOHRtMJk"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/Data/training_checkpoints /content/Data/training_checkpoints"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2020_05_16_PGWGAN-PG_EfficientClass_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
